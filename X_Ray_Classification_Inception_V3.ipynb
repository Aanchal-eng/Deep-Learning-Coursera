{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "X Ray Classification- Inception V3",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1azBlYHc9GJ8NJXSef7OMvwiOURNmOrF2",
      "authorship_tag": "ABX9TyPBKjMZeS/3HU4loYDrTLkH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aanchal-eng/Deep-Learning-Coursera/blob/master/X_Ray_Classification_Inception_V3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9KJHkNWlLMb"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Reshape, Dropout, Dense,Multiply, Dot, Concatenate,Embedding\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPool2D,SeparableConv2D, ReLU, Add,GlobalAvgPool2D, Input,BatchNormalization \n",
        "#from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPool2D, SeparableConv2D,  BatchNormalization, Input, GlobalAveragePool2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import ImageTk, Image"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bUpozw_l068",
        "outputId": "51ee8aec-bc7b-456b-cce6-ee780a45e223",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.3.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eIHxP4pNZv5"
      },
      "source": [
        "train_image_generator = ImageDataGenerator(\n",
        "                                              rotation_range=40,\n",
        "                                              width_shift_range=0.2,\n",
        "                                              height_shift_range=0.2,\n",
        "                                              rescale=1./255,\n",
        "                                              shear_range=0.2,\n",
        "                                              zoom_range=0.2,\n",
        "                                              horizontal_flip=True,\n",
        "                                              fill_mode='nearest')\n",
        "validation_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our validation data"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo67Z6PWNrUr",
        "outputId": "b10dba23-eb2b-45da-88c3-0a154fff2432",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_data_gen = train_image_generator.flow_from_directory(batch_size=32,\n",
        "                                                           directory='/content/drive/My Drive/chest_xray/train',\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(256, 256),\n",
        "                                                           class_mode='binary')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5263 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWbuJiSNN4y_",
        "outputId": "a040e5ec-c906-4ddb-af83-3e02cbd76c23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "test_data_gen = validation_image_generator.flow_from_directory(batch_size=32,\n",
        "                                                           directory='/content/drive/My Drive/chest_xray/test',\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(256, 256),\n",
        "                                                           class_mode='binary')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 624 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tfmnVGhOPYy",
        "outputId": "f9861003-cc38-46bc-f4fa-11f08808aad7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Let's look at how many cats and dogs images are in the training and validation directory:\n",
        "total_train = train_data_gen.samples\n",
        "total_val = test_data_gen.samples\n",
        "print(\"Total training images:\", total_train)\n",
        "print(\"Total validation images:\", total_val)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total training images: 5263\n",
            "Total validation images: 624\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggiuXAv1OoF_"
      },
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import tensorflow as tf\n",
        "from keras.utils import np_utils\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import cv2"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcE8F7XiOxyz"
      },
      "source": [
        "#@title Default title text\n",
        "conv_base = InceptionV3(weights='imagenet', include_top=False, input_shape=(256, 256, 3))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyBhot_2PB6a"
      },
      "source": [
        "conv_base.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmtS7zf0PNWR",
        "outputId": "5192d13d-edc2-4832-808d-620c387732b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.Flatten(input_shape=(256,256,3)))\n",
        "model.add(layers.Dense(128, activation='tanh'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=2e-5), loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "history = model.fit(train_data_gen, steps_per_epoch=5, epochs=20, batch_size=30, validation_data=test_data_gen)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "5/5 [==============================] - 175s 35s/step - loss: 0.7805 - acc: 0.5125 - val_loss: 0.6588 - val_acc: 0.5897\n",
            "Epoch 2/20\n",
            "5/5 [==============================] - 162s 32s/step - loss: 0.6776 - acc: 0.6224 - val_loss: 0.6409 - val_acc: 0.6378\n",
            "Epoch 3/20\n",
            "5/5 [==============================] - 180s 36s/step - loss: 0.6484 - acc: 0.6750 - val_loss: 0.6528 - val_acc: 0.6218\n",
            "Epoch 4/20\n",
            "5/5 [==============================] - 179s 36s/step - loss: 0.7093 - acc: 0.6562 - val_loss: 0.6313 - val_acc: 0.6458\n",
            "Epoch 5/20\n",
            "5/5 [==============================] - 175s 35s/step - loss: 0.5957 - acc: 0.7125 - val_loss: 0.6166 - val_acc: 0.6779\n",
            "Epoch 6/20\n",
            "5/5 [==============================] - 171s 34s/step - loss: 0.7069 - acc: 0.6313 - val_loss: 0.6033 - val_acc: 0.7099\n",
            "Epoch 7/20\n",
            "5/5 [==============================] - 171s 34s/step - loss: 0.6040 - acc: 0.7125 - val_loss: 0.5751 - val_acc: 0.7019\n",
            "Epoch 8/20\n",
            "5/5 [==============================] - 174s 35s/step - loss: 0.7181 - acc: 0.6438 - val_loss: 0.5657 - val_acc: 0.7212\n",
            "Epoch 9/20\n",
            "5/5 [==============================] - 172s 34s/step - loss: 0.5296 - acc: 0.7250 - val_loss: 0.5442 - val_acc: 0.7196\n",
            "Epoch 10/20\n",
            "5/5 [==============================] - 171s 34s/step - loss: 0.5994 - acc: 0.7250 - val_loss: 0.5546 - val_acc: 0.7131\n",
            "Epoch 11/20\n",
            "5/5 [==============================] - 171s 34s/step - loss: 0.5550 - acc: 0.7437 - val_loss: 0.5415 - val_acc: 0.7196\n",
            "Epoch 12/20\n",
            "5/5 [==============================] - 176s 35s/step - loss: 0.5172 - acc: 0.7688 - val_loss: 0.5467 - val_acc: 0.7196\n",
            "Epoch 13/20\n",
            "5/5 [==============================] - 173s 35s/step - loss: 0.6167 - acc: 0.6938 - val_loss: 0.5408 - val_acc: 0.7324\n",
            "Epoch 14/20\n",
            "5/5 [==============================] - 171s 34s/step - loss: 0.6048 - acc: 0.6875 - val_loss: 0.5374 - val_acc: 0.7260\n",
            "Epoch 15/20\n",
            "5/5 [==============================] - 172s 34s/step - loss: 0.6405 - acc: 0.7125 - val_loss: 0.5429 - val_acc: 0.7212\n",
            "Epoch 16/20\n",
            "5/5 [==============================] - 174s 35s/step - loss: 0.5748 - acc: 0.7188 - val_loss: 0.5410 - val_acc: 0.7308\n",
            "Epoch 17/20\n",
            "5/5 [==============================] - 173s 35s/step - loss: 0.5967 - acc: 0.6938 - val_loss: 0.5428 - val_acc: 0.7212\n",
            "Epoch 18/20\n",
            "5/5 [==============================] - 181s 36s/step - loss: 0.5119 - acc: 0.7812 - val_loss: 0.5294 - val_acc: 0.7276\n",
            "Epoch 19/20\n",
            "5/5 [==============================] - 173s 35s/step - loss: 0.5141 - acc: 0.7500 - val_loss: 0.5069 - val_acc: 0.7500\n",
            "Epoch 20/20\n",
            "5/5 [==============================] - 171s 34s/step - loss: 0.4117 - acc: 0.8188 - val_loss: 0.5286 - val_acc: 0.7356\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}